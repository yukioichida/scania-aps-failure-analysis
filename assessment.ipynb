{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base methods to deal with the test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base methods to deal with preprocessing data\n",
    "- **fill_gaps** : *Method that deals with missing data from a dataframe*\n",
    "- **normalize** : *Method that normalize data rescaling numerical values to a predefined range*\n",
    "- **pca** : *Method that applies pca in a dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_gaps(df, empty_token = '?'):\n",
    "    imputer = SimpleImputer(missing_values = empty_token, strategy = 'most_frequent')\n",
    "    result = imputer.fit_transform(df)\n",
    "    \n",
    "    result_df = DataFrame(result)\n",
    "    result_df.columns = df.columns\n",
    "    result_df.index = df.index\n",
    "    return result_df\n",
    "\n",
    "def normalize(df, columns, range=(0,1)):\n",
    "    scaler = MinMaxScaler(feature_range=range)\n",
    "    for col in columns:\n",
    "        scaled_values = scaler.fit_transform(df[[col]].values.astype(float))\n",
    "        df[col] = scaled_values\n",
    "    return df\n",
    "\n",
    "def pca(df, components = 70):\n",
    "    pca = PCA(n_components = components)\n",
    "    pca_values = pca.fit_transform(df)\n",
    "    component_cols = []\n",
    "    for i in range(0, components):\n",
    "        component_cols.append('component_%s'%i)\n",
    "    return DataFrame(data = pca_values, columns = component_cols)\n",
    "\n",
    "def cost(fp, fn):\n",
    "    return (fp * 2) + fn\n",
    "\n",
    "def train_classifier(pre_train_df, pre_test_df):\n",
    "    x_train = pre_train_df.iloc[:, 1:].values\n",
    "    y_train = pre_train_df['class'].values\n",
    "\n",
    "    x_test = pre_test_df.iloc[:, 1:].values\n",
    "    y_test = pre_test_df['class'].values\n",
    "\n",
    "    t1_classifier = DecisionTreeClassifier()\n",
    "    t1_classifier.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = t1_classifier.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    display(\"Accuracy %s\" % (accuracy))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_pred, y_test).ravel()\n",
    "    display(\"Cost: %s\" % (cost(fp, fn)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"aps_training_set_sample3.csv\")\n",
    "test_df = pd.read_csv(\"aps_failure_test_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing classes in train dataset by resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive samples: 1000 - Negative samples: 2091'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Using 1000 samples per class'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "neg    1000\n",
       "pos    1000\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2000, 171)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to balance the classes \n",
    "positive_class = train_df[train_df['class'] == 'pos']\n",
    "qtd_pos = positive_class.shape[0]\n",
    "negative_class = train_df[train_df['class'] == 'neg']\n",
    "qtd_neg = negative_class.shape[0]\n",
    "\n",
    "display(\"Positive samples: %s - Negative samples: %s\" %(qtd_pos, qtd_neg))\n",
    "new_samples = min(qtd_neg, qtd_pos)\n",
    "display(\"Using %s samples per class\" % (new_samples))\n",
    "\n",
    "\n",
    "train_df = pd.concat([positive_class[:new_samples], negative_class[:new_samples]], ignore_index = True)\n",
    "display(train_df['class'].value_counts())\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case 1\n",
    "- fill_gaps\n",
    "- Using DecisionTreeClassifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    1000\n",
       "pos    1000\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy 0.9291875'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Cost: 1154'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_train_df = fill_gaps(train_df)\n",
    "pre_test_df = fill_gaps(test_df)\n",
    "\n",
    "display(pre_train_df['class'].value_counts())\n",
    "\n",
    "train_classifier(pre_train_df, pre_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case 2\n",
    "- fill_gaps\n",
    "- normalizing top 10 std_dev columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ac_000    5.943633e+08\n",
       "dq_000    2.818990e+08\n",
       "eb_000    1.113884e+08\n",
       "bb_000    3.246790e+07\n",
       "bv_000    3.235481e+07\n",
       "cq_000    3.235481e+07\n",
       "bu_000    3.235481e+07\n",
       "bx_000    3.090717e+07\n",
       "cc_000    2.912746e+07\n",
       "du_000    2.895663e+07\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy 0.9325625'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Cost: 1100'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_train_df = fill_gaps(train_df)\n",
    "# Ignoring first column that is the label\n",
    "for c in pre_train_df.columns[1:].values:\n",
    "    pre_train_df[c] = pd.to_numeric(pre_train_df[c])\n",
    "    \n",
    "std_df = pre_train_df.std(axis = 0, skipna=True)\n",
    "top10_std = std_df.sort_values(ascending=[False])[:10]\n",
    "display(top10_std)\n",
    "top10_std_columns = top10_std.index\n",
    "pre_train_df = normalize(pre_train_df, columns = top10_std_columns)\n",
    "\n",
    "pre_test_df = fill_gaps(test_df)\n",
    "pre_test_df = normalize(pre_test_df, columns = top10_std_columns)\n",
    "\n",
    "train_classifier(pre_train_df, pre_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Case 3\n",
    "- fill gaps\n",
    "- normalizing top 10 std_dev columns\n",
    "- dimensionality reduction through pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy 0.0233125'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Cost: 15646'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_train_df = pca(pre_train_df.loc[:, pre_train_df.columns != 'class'])\n",
    "pca_test_df = pca(pre_test_df.loc[:, pre_train_df.columns != 'class'])\n",
    "\n",
    "pca_train_df = pd.concat([pre_train_df['class'], pca_train_df], axis=1)\n",
    "pca_test_df = pd.concat([pre_test_df['class'], pca_test_df], axis = 1)\n",
    "\n",
    "train_classifier(pca_train_df, pca_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
